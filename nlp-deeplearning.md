# NLP with Deep learning

In the autumn of 2019 the participants of the [Natural Language Processing SIG](https://github.com/NLeSC/ehumanities-sig/) follow the course [CS224n: Natural Language Processing with Deep Learning](https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z) from Stanford University. This is an overview of the lessons that we have viewed.

We meet at Thursdays 14:00-15:30 in the room Compass (or Collab).

## 20200430 Lecture 17 (room: Collab)

Link to: [course video](https://www.youtube.com/watch?v=M8dsZsEtEsg) (**Multitask Learning**)

Planned slide selection:

* 00:00-1:11:53 Multitask Learning

## 20200423 meeting cancelled

## 20200416 meeting cancelled

## 20200409 meeting cancelled

## 20200402 meeting cancelled

## 20200326 meeting cancelled

## 20200319 meeting cancelled

## 20200312 Lecture 16 (room: Compass)

Link to: [course video](https://www.youtube.com/watch?v=i19m4GzBhfc) (**Coreference resolution**)

Planned slide selection:

* 01:40-1:19:20 Coreference resolution

Skipped: 00:00-01:40 course announcements

## 20200305 Lecture 15 (room: Compass!)

Link to: [course video](https://www.youtube.com/watch?v=4uG1NMKNWCU) (**Natural Language Generation**)

Planned slide selection:

* 01:09-1:19:36 Natural Language Generation

Skipped: 00:00-01:09 course announcements

## 20200227 Lecture 14 (room: Collab)

Link to: [course video](https://www.youtube.com/watch?v=5vcj8kSwBCY) (**Transformers and Self-Attention**)

Planned slide selection:

* 00:00-53:47 Transformers and Self-Attention

Paper tip: [oLMpics - On what Language Model Pre-training Captures](https://arxiv.org/pdf/1912.13283.pdf)

## 20200220 Lecture 13 (room: Collab)

Link to: [course video](https://www.youtube.com/watch?v=S-CspeZ8FHc) (**Contextual Word Representations**)

Planned slide selection:

* 05:00-1:20:18 Contextual Word Representations and Pre-training: Elmo and Bert

Skipped: 00:00-05:00 course announcements

Recommended [notebook](http://nlp.seas.harvard.edu/2018/04/03/attention.html) related to the paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762)

## 20200213 Lecture 12 (room: Compass!)

Link to: [course video](https://www.youtube.com/watch?v=9oTHFx0Gg3Q) (**Subword Models**)

Planned slide selection:

* 03:52-1:15:29 Subword models

Skipped: 00:00-03:52 course announcements

## 20200206 meeting cancelled

## 20191209 Lecture 11

Link to: [course video](https://www.youtube.com/watch?v=EAJoRA0KX7I) (**Convolutional Networks for NLP**)

Planned slide selection:

* 07:56-1:20:18 Convolutional NN

Skipped: 00:00-07:56 deep NN good practice is still shifting &amp; [Pytorch NLP book](http://shop.oreilly.com/product/0636920063445.do)

Upcoming:

12. Subword Models
13. Contextual Word Embeddings
14. Transformers and Self-Attention
15. Natural Language Generation
16. Coreference Resolution
17. Multitask Learning
18. Consituency Parsing, TreeRNNs
19. Bias in AI
20. Future of NLP + Deep Learning

## 20191202 Lecture 10

Link to: [course video](https://www.youtube.com/watch?v=yIdF-17HwSk) (**Question Answering**)

Planned slide selection:

* 06:19-1:21:00 Question Answering with NN

Skipped: 00:00-06:19 course announcements

## 20191125 meeting cancelled

## 20191118 meeting cancelled

## 20191111 Lecture 9

Link to: [course video](https://www.youtube.com/watch?v=fyqm8fRDgl0) (**Practical Tips for Projects**)

Planned slide selection:

* 36:36-59:10: Gated Recurrent Units, Vocabulary sizes 
* 59:10-1:07:40: Evaluation of Machine Translation (optional)
* 1:11:44-1:18:08: Data set splits (optional)

Skipped: 00:00-36:36, 1:07:40-1:11:44, 1:18:08-END: course announcements

## 20191104 Lecture 8

Link to: [course video](https://www.youtube.com/watch?v=XXtpJxZBa2c) (**Translation, Seq2Seq, Attention**)

Planned slide selection:

* 01:06-END:   Statistical Machine Translation and Neural Machine Translation

Skipped: 00:00-01:06 course announcements

## 20191028 Lecture 7

Link to: [course video](https://www.youtube.com/watch?v=QEw0qEa0E50) (**Vanishing Gradients, Fancy RNNs**)

Planned slide selection:

* 03:06-END:   RNN problems &amp; solutions

Skipped: 00:00-03:06: course announcements

## 20191021 meeting cancelled

## 20191014 Lecture 6 (starts at 13:30)

Link to: [course video](https://www.youtube.com/watch?v=iWea12EAu6U) (**Language Models and RNN's**)

Planned slide selection:

* 15:07-END:   Language models &amp; recurrent neural networks

Skipped: 00:00-15:07: language models, ngram models and smoothing

## 20191007 Lecture 5

Link to: [course video](https://www.youtube.com/watch?v=nC9_RfjYwqA) (**Dependency parsing**)

Planned slide selection:

* 50:54-END:   Dependency parsing &amp; Neural parsing

Skipped: 00:00-50:54: Introduction to NLP

## 20190930 Lecture 4

Link to: [course video](https://www.youtube.com/watch?v=yLYHDSv-288) (**Backpropagation**)

Planned slide selection:

* 00:00-END:   Backpropagation &amp; Tips

Also:

* Gensim word vector demo: 
  \[[code](http://web.stanford.edu/class/cs224n/materials/Gensim.zip)\]
  \[[data](http://nlp.stanford.edu/data/glove.6B.zip)\]
* Andrej Karpathy's blog post [Yes you should understand backprop](https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b)

## 20190923 Lecture 3 (starts at 13:30)

Link to: [course video](https://www.youtube.com/watch?v=8CWyBNX6eDo) (**Neural networks**)

Planned slide selection:

* 00:00-02:02: Course plan
* 04:44-END:   Feed forward networks and named entity recognition

## 20190916 Lecture 2

Link to: [course video](https://www.youtube.com/watch?v=kEMJRjEdNzM) (**Word Vectors and Word Senses**)

Planned slide selection:

* 00:00-END: Word vectors and word senses

## 20190909 Lecture 1

Link to: [course video](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z) (**Introduction and Word Vectors**)

Planned slide selection:

* 03:52:      Course goals
* 09:00:      Assignments
* 10:00-44:00: Introduction
* 74:08-END:  Assignment 1 (download from [course page](http://web.stanford.edu/class/cs224n/))

Skipped: 00:00-10:00 and 44:00-74:08.
